{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ekphrasis in /Users/PhilipADSo/anaconda3/lib/python3.6/site-packages (0.5.1)\n",
      "Requirement already satisfied: numpy in /Users/PhilipADSo/anaconda3/lib/python3.6/site-packages (from ekphrasis) (1.16.2)\n",
      "Requirement already satisfied: nltk in /Users/PhilipADSo/anaconda3/lib/python3.6/site-packages (from ekphrasis) (3.3)\n",
      "Requirement already satisfied: tqdm in /Users/PhilipADSo/anaconda3/lib/python3.6/site-packages (from ekphrasis) (4.31.1)\n",
      "Requirement already satisfied: ftfy in /Users/PhilipADSo/anaconda3/lib/python3.6/site-packages (from ekphrasis) (5.5.1)\n",
      "Requirement already satisfied: matplotlib in /Users/PhilipADSo/anaconda3/lib/python3.6/site-packages (from ekphrasis) (2.2.2)\n",
      "Requirement already satisfied: colorama in /Users/PhilipADSo/anaconda3/lib/python3.6/site-packages (from ekphrasis) (0.3.9)\n",
      "Requirement already satisfied: ujson in /Users/PhilipADSo/anaconda3/lib/python3.6/site-packages (from ekphrasis) (1.35)\n",
      "Requirement already satisfied: termcolor in /Users/PhilipADSo/anaconda3/lib/python3.6/site-packages (from ekphrasis) (1.1.0)\n",
      "Requirement already satisfied: six in /Users/PhilipADSo/anaconda3/lib/python3.6/site-packages (from nltk->ekphrasis) (1.11.0)\n",
      "Requirement already satisfied: wcwidth in /Users/PhilipADSo/anaconda3/lib/python3.6/site-packages (from ftfy->ekphrasis) (0.1.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/PhilipADSo/anaconda3/lib/python3.6/site-packages (from matplotlib->ekphrasis) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /Users/PhilipADSo/anaconda3/lib/python3.6/site-packages (from matplotlib->ekphrasis) (2.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /Users/PhilipADSo/anaconda3/lib/python3.6/site-packages (from matplotlib->ekphrasis) (2.7.3)\n",
      "Requirement already satisfied: pytz in /Users/PhilipADSo/anaconda3/lib/python3.6/site-packages (from matplotlib->ekphrasis) (2018.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/PhilipADSo/anaconda3/lib/python3.6/site-packages (from matplotlib->ekphrasis) (1.0.1)\n",
      "Requirement already satisfied: setuptools in /Users/PhilipADSo/anaconda3/lib/python3.6/site-packages (from kiwisolver>=1.0.1->matplotlib->ekphrasis) (39.1.0)\n",
      "\u001b[33mYou are using pip version 18.1, however version 19.0.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: gensim in /Users/PhilipADSo/anaconda3/lib/python3.6/site-packages (3.7.2)\n",
      "Requirement already satisfied: smart-open>=1.7.0 in /Users/PhilipADSo/anaconda3/lib/python3.6/site-packages (from gensim) (1.8.1)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /Users/PhilipADSo/anaconda3/lib/python3.6/site-packages (from gensim) (1.1.0)\n",
      "Requirement already satisfied: six>=1.5.0 in /Users/PhilipADSo/anaconda3/lib/python3.6/site-packages (from gensim) (1.11.0)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /Users/PhilipADSo/anaconda3/lib/python3.6/site-packages (from gensim) (1.16.2)\n",
      "Requirement already satisfied: boto>=2.32 in /Users/PhilipADSo/anaconda3/lib/python3.6/site-packages (from smart-open>=1.7.0->gensim) (2.48.0)\n",
      "Requirement already satisfied: requests in /Users/PhilipADSo/anaconda3/lib/python3.6/site-packages (from smart-open>=1.7.0->gensim) (2.18.4)\n",
      "Requirement already satisfied: bz2file in /Users/PhilipADSo/anaconda3/lib/python3.6/site-packages (from smart-open>=1.7.0->gensim) (0.98)\n",
      "Requirement already satisfied: boto3 in /Users/PhilipADSo/anaconda3/lib/python3.6/site-packages (from smart-open>=1.7.0->gensim) (1.9.130)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/PhilipADSo/anaconda3/lib/python3.6/site-packages (from requests->smart-open>=1.7.0->gensim) (3.0.4)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /Users/PhilipADSo/anaconda3/lib/python3.6/site-packages (from requests->smart-open>=1.7.0->gensim) (2.6)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /Users/PhilipADSo/anaconda3/lib/python3.6/site-packages (from requests->smart-open>=1.7.0->gensim) (1.22)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/PhilipADSo/anaconda3/lib/python3.6/site-packages (from requests->smart-open>=1.7.0->gensim) (2018.4.16)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /Users/PhilipADSo/anaconda3/lib/python3.6/site-packages (from boto3->smart-open>=1.7.0->gensim) (0.9.4)\n",
      "Requirement already satisfied: botocore<1.13.0,>=1.12.130 in /Users/PhilipADSo/anaconda3/lib/python3.6/site-packages (from boto3->smart-open>=1.7.0->gensim) (1.12.130)\n",
      "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /Users/PhilipADSo/anaconda3/lib/python3.6/site-packages (from boto3->smart-open>=1.7.0->gensim) (0.2.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /Users/PhilipADSo/anaconda3/lib/python3.6/site-packages (from botocore<1.13.0,>=1.12.130->boto3->smart-open>=1.7.0->gensim) (2.7.3)\n",
      "Requirement already satisfied: docutils>=0.10 in /Users/PhilipADSo/anaconda3/lib/python3.6/site-packages (from botocore<1.13.0,>=1.12.130->boto3->smart-open>=1.7.0->gensim) (0.14)\n",
      "\u001b[33mYou are using pip version 18.1, however version 19.0.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: tabulate in /Users/PhilipADSo/anaconda3/lib/python3.6/site-packages (0.8.3)\n",
      "\u001b[33mYou are using pip version 18.1, however version 19.0.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/PhilipADSo/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/PhilipADSo/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Download and import required libraries\n",
    "!pip install ekphrasis\n",
    "!pip install gensim\n",
    "%matplotlib inline\n",
    "!pip install tabulate\n",
    "from tabulate import tabulate\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import struct \n",
    "\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import io, re\n",
    "\n",
    "from ekphrasis.classes.preprocessor import TextPreProcessor\n",
    "from ekphrasis.classes.tokenizer import SocialTokenizer\n",
    "from ekphrasis.dicts.emoticons import emoticons\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import LancasterStemmer, WordNetLemmatizer\n",
    "import nltk\n",
    "\n",
    "import itertools\n",
    "\n",
    "#Download required lists for preprocessing\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "#Set path of GloVe vectors\n",
    "GLOVE_wiki50d_PATH = \"glove.6B/glove.6B.50d.txt\"\n",
    "GLOVE_wiki200d_PATH = \"glove.6B/glove.6B.200d.txt\"\n",
    "\n",
    "encoding=\"utf-8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download required GloVe vectors\n",
    "# Can alreadt found in the glove.6B folder\n",
    "#!pip install wget\n",
    "#import zipfile\n",
    "#import wget\n",
    "# download GloVe word vector representations\n",
    "#wget.download('http://nlp.stanford.edu/data/glove.6B.zip')\n",
    "#zipped = zipfile.ZipFile('glove.6B.zip')\n",
    "#zipped.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert emotion labels\n",
    "label2emotion = {0:\"others\", 1:\"happy\", 2: \"sad\", 3:\"angry\"}\n",
    "emotion2label = {\"others\":0, \"happy\":1, \"sad\":2, \"angry\":3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocess data\n",
    "#script used from original code used in https://competitions.codalab.org/competitions/19790#learn_the_details-data-set-format\n",
    "def preprocessData(dataFilePath, mode):\n",
    "    \"\"\"Load data from a file, process and return indices, conversations and labels in separate lists\n",
    "    Input:\n",
    "        dataFilePath : Path to train/test file to be processed\n",
    "        mode : \"train\" mode returns labels. \"test\" mode doesn't return labels.\n",
    "    Output:\n",
    "        indices : Unique conversation ID list\n",
    "        conversations : List of 3 turn conversations, processed and each turn separated by the <eos> tag\n",
    "        labels : [Only available in \"train\" mode] List of labels\n",
    "    \"\"\"\n",
    "    indices = []\n",
    "    conversations = []\n",
    "    labels = []\n",
    "    with io.open(dataFilePath, encoding=\"utf8\") as finput:\n",
    "        finput.readline()\n",
    "        for line in finput:\n",
    "            # Convert multiple instances of . ? ! , to single instance\n",
    "            # okay...sure -> okay . sure\n",
    "            # okay???sure -> okay ? sure\n",
    "            # Add whitespace around such punctuation\n",
    "            # okay!sure -> okay ! sure\n",
    "            repeatedChars = ['.', '?', '!', ',']\n",
    "            for c in repeatedChars:\n",
    "                lineSplit = line.split(c)\n",
    "                while True:\n",
    "                    try:\n",
    "                        lineSplit.remove('')\n",
    "                    except:\n",
    "                        break\n",
    "                cSpace = ' ' + c + ' '    \n",
    "                line = cSpace.join(lineSplit)\n",
    "            \n",
    "            line = line.strip().split('\\t')\n",
    "            if mode == \"train\":\n",
    "                # Train data contains id, 3 turns and label\n",
    "                label = emotion2label[line[4]]\n",
    "                labels.append(label)\n",
    "            \n",
    "            conv = ' <eos> '.join(line[1:4])\n",
    "            \n",
    "            # Remove any duplicate spaces\n",
    "            duplicateSpacePattern = re.compile(r'\\ +')\n",
    "            conv = re.sub(duplicateSpacePattern, ' ', conv)\n",
    "            \n",
    "            indices.append(int(line[0]))\n",
    "            conversations.append(conv.lower())\n",
    "    \n",
    "    if mode == \"train\":\n",
    "        return indices, conversations, labels\n",
    "    else:\n",
    "        return indices, conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import data\n",
    "trainIndices, trainTexts, labels = preprocessData(\"train.txt\", mode=\"train\")\n",
    "testIndices, testTexts, testLabels = preprocessData(\"test.txt\", mode=\"train\")\n",
    "devIndices, devTexts, devLabels = preprocessData(\"test.txt\", mode=\"train\")\n",
    "\n",
    "#Combining dev and test set to be re-split in training\n",
    "trainTexts += testTexts + devTexts\n",
    "labels+= testLabels + devLabels\n",
    "\n",
    "trainDF = pd.DataFrame({'convtrain': trainTexts,'labels': labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stemming, lemmatisation and removing stopwords\n",
    "def remove_stopwords(words):\n",
    "    \"\"\"Remove stop words from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word not in stopwords.words('english'):\n",
    "            new_words.append(word)\n",
    "    return new_words\n",
    "\n",
    "def stem_words(words):\n",
    "    \"\"\"Stem words in list of tokenized words\"\"\"\n",
    "    stemmer = LancasterStemmer()\n",
    "    stems = []\n",
    "    for word in words:\n",
    "        stem = stemmer.stem(word)\n",
    "        stems.append(stem)\n",
    "    return stems\n",
    "\n",
    "def lemmatize_verbs(words):\n",
    "    \"\"\"Lemmatize verbs in list of tokenized words\"\"\"\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmas = []\n",
    "    for word in words:\n",
    "        lemma = lemmatizer.lemmatize(word, pos='v')\n",
    "        lemmas.append(lemma)\n",
    "    return lemmas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading twitter - 1grams ...\n",
      "Reading twitter - 2grams ...\n",
      "Reading twitter - 1grams ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/PhilipADSo/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:40: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n"
     ]
    }
   ],
   "source": [
    "#Ekphrasis pre-processing and apply other preprocessing\n",
    "#https://github.com/cbaziotis/ekphrasis\n",
    "all_words = []  \n",
    "sentences = []\n",
    "text_processor = TextPreProcessor(\n",
    "    # terms that will be normalized\n",
    "    normalize=['url', 'email', 'percent', 'money', 'phone', 'user',\n",
    "        'time', 'url', 'date', 'number'],\n",
    "    # terms that will be annotated\n",
    "    annotate={\"hashtag\", \"allcaps\", \"elongated\", \"repeated\",\n",
    "        'emphasis', 'censored'},\n",
    "    fix_html=True,  # fix HTML tokens\n",
    "    \n",
    "    # corpus from which the word statistics are going to be used \n",
    "    # for word segmentation \n",
    "    segmenter=\"twitter\", \n",
    "    \n",
    "    # corpus from which the word statistics are going to be used \n",
    "    # for spell correction\n",
    "    corrector=\"twitter\", \n",
    "    \n",
    "    unpack_hashtags=True,  # perform word segmentation on hashtags\n",
    "    unpack_contractions=True,  # Unpack contractions (can't -> can not)\n",
    "    spell_correct_elong=False,  # spell correction for elongated words\n",
    "    \n",
    "    # select a tokenizer. You can use SocialTokenizer, or pass your own\n",
    "    # the tokenizer, should take as input a string and return a list of tokens\n",
    "    tokenizer=SocialTokenizer(lowercase=True).tokenize,\n",
    "    \n",
    "    # list of dictionaries, for replacing tokens extracted from the text,\n",
    "    # with other expressions. You can pass more than one dictionaries.\n",
    "    dicts=[emoticons]\n",
    ")\n",
    "\n",
    "  \n",
    "for index, row in trainDF.iterrows():\n",
    "    tokenized = text_processor.pre_process_doc(row['convtrain'])\n",
    "    preprocessed = lemmatize_verbs(stem_words(remove_stopwords(tokenized)))\n",
    "    all_words.append(preprocessed)\n",
    "    sentences.append(preprocessed)\n",
    "    trainDF.set_value(index,'convtrain',preprocessed)\n",
    "\n",
    "all_words = list(itertools.chain(*all_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainset-sample size: 97208 \n"
     ]
    }
   ],
   "source": [
    "# Confirm size of dataset\n",
    "print('Trainset-sample size: {} '.\\\n",
    "      format(trainDF.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Train  Train_% Labelsn\n",
      "3  24302     25.0  Others\n",
      "2  24302     25.0   Angry\n",
      "1  24302     25.0     Sad\n",
      "0  24302     25.0   Happy\n"
     ]
    }
   ],
   "source": [
    "#Print data stats\n",
    "def column_value_counts(df, target_column, new_column):\n",
    "    '''\n",
    "    Get value counts of each categorical variable. Store this data in \n",
    "    a dataframe. Also add a column with relative percentage of each \n",
    "    categorical variable.\n",
    "    \n",
    "    :param df: A Pandas dataframe\n",
    "    :param target_column: Name of the column in the original dataframe (string)\n",
    "    :param new_column: Name of the new column where the frequency counts are stored \n",
    "    :type df: pandas.core.frame.DataFrame\n",
    "    :type target_column: str\n",
    "    :type new_column: str\n",
    "    :return: A Pandas dataframe containing the frequency counts\n",
    "    :rtype: pandas.core.frame.DataFrame\n",
    "    '''\n",
    "    df_value_counts = df[target_column].value_counts()\n",
    "    df = pd.DataFrame(df_value_counts)\n",
    "    df.columns = [new_column]\n",
    "    df[new_column+'_%'] = 100*df[new_column] / df[new_column].sum()\n",
    "    return df\n",
    "\n",
    "# Get frequency distribution of labels in each set\n",
    "df_train = column_value_counts(trainDF, 'labels', 'Train')\n",
    "# df_test = column_value_counts(testDF, 'labels', 'Test')\n",
    "\n",
    "label_count = pd.concat([df_train], axis=1) # Merge dataframes by index\n",
    "label_count = label_count.fillna(0) # Replace Nan with 0 (zero)\n",
    "label_count = label_count.round(2) # Rounding decimals to two digits after .\n",
    "label_count['Labelsn'] = ['Others','Angry','Sad','Happy']\n",
    "print(label_count.sort_values(by=['Train'], ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads the download GloVe files line by line and\n",
    "# selects vectors that only correspond to the dataset\n",
    "# If statement reduces the req amount of RAM\n",
    "\n",
    "glove_small = {}\n",
    "with open(GLOVE_wiki50d_PATH, \"rb\") as infile:\n",
    "    for line in infile:\n",
    "        parts = line.split()\n",
    "        word = parts[0].decode(encoding)\n",
    "        \n",
    "        if (word in all_words):\n",
    "            nums=np.array(parts[1:], dtype=np.float32)\n",
    "            glove_small[word] = nums\n",
    "\n",
    "            \n",
    "glove_big = {}\n",
    "with open(GLOVE_wiki200d_PATH, \"rb\") as infile:\n",
    "    for line in infile:\n",
    "        parts = line.split()\n",
    "        word = parts[0].decode(encoding)\n",
    "        \n",
    "        if word in all_words:\n",
    "            nums=np.array(parts[1:], dtype=np.float32)\n",
    "            glove_big[word] = nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saves new vectors to file\n",
    "filename1 = 'glove_small'\n",
    "outfile1 = open(filename1,'wb')\n",
    "pickle.dump(glove_small,outfile1)\n",
    "outfile1.close()\n",
    "\n",
    "filename2 = 'glove_big'\n",
    "outfile2 = open(filename2,'wb')\n",
    "pickle.dump(glove_big,outfile2)\n",
    "outfile2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads vecrtors from file\n",
    "glove_small = pickle.load( open( \"glove_small\", \"rb\" ) )\n",
    "glove_big = pickle.load( open( \"glove_big\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectoriser classes\n",
    "# Word count vectoriser\n",
    "class MeanEmbeddingVectorizer(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        if len(word2vec)>0:\n",
    "            self.dim=len(word2vec[next(iter(glove_small))])\n",
    "        else:\n",
    "            self.dim=0\n",
    "            \n",
    "    def fit(self, X, y):\n",
    "        return self \n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "            np.mean([self.word2vec[w] for w in words if w in self.word2vec] \n",
    "                    or [np.zeros(self.dim)], axis=0)\n",
    "            for words in X\n",
    "        ])\n",
    "\n",
    "    \n",
    "# TD-IDF vectoriser\n",
    "class TfidfEmbeddingVectorizer(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        self.word2weight = None\n",
    "        if len(word2vec)>0:\n",
    "            self.dim=len(word2vec[next(iter(glove_small))])\n",
    "        else:\n",
    "            self.dim=0\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        tfidf = TfidfVectorizer(analyzer=lambda x: x)\n",
    "        tfidf.fit(X)\n",
    "        max_idf = max(tfidf.idf_)\n",
    "        self.word2weight = defaultdict(\n",
    "            lambda: max_idf, \n",
    "            [(w, tfidf.idf_[i]) for w, i in tfidf.vocabulary_.items()])\n",
    "    \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "                np.mean([self.word2vec[w] * self.word2weight[w]\n",
    "                         for w in words if w in self.word2vec] or\n",
    "                        [np.zeros(self.dim)], axis=0)\n",
    "                for words in X\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = Pipeline([(\"count_vectorizer\", CountVectorizer(analyzer=lambda x: x)), (\"linear svc\", SVC(kernel=\"linear\", class_weight=\"balanced\"))])\n",
    "svc_tfidf = Pipeline([(\"tfidf_vectorizer\", TfidfVectorizer(analyzer=lambda x: x)), (\"linear svc\", SVC(kernel=\"linear\", class_weight=\"balanced\"))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need\n",
    "glove_small_svm = Pipeline([(\"glove vectorizer\", MeanEmbeddingVectorizer(glove_small)), \n",
    "                        (\"linear svc\", SVC(kernel=\"linear\", class_weight=\"balanced\"))])\n",
    "glove_small_tfidf_svm = Pipeline([(\"glove vectorizer\", TfidfEmbeddingVectorizer(glove_small)), \n",
    "                        (\"linear svc\", SVC(kernel=\"linear\", class_weight=\"balanced\"))])\n",
    "\n",
    "glove_big_svm = Pipeline([(\"glove vectorizer\", MeanEmbeddingVectorizer(glove_big)), \n",
    "                        (\"linear svc\", SVC(kernel=\"linear\", class_weight=\"balanced\"))])\n",
    "glove_big_tfidf_svm = Pipeline([(\"glove vectorizer\", TfidfEmbeddingVectorizer(glove_big)), \n",
    "                        (\"linear svc\", SVC(kernel=\"linear\", class_weight=\"balanced\"))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need\n",
    "all_models = [\n",
    "\n",
    "    (\"svc\", svc),\n",
    "    (\"svc_tfidf\", svc_tfidf),\n",
    "    (\"glove_small_svm\" , glove_small_svm),\n",
    "    (\"glove_small_tfidf_svm\", glove_small_tfidf_svm),\n",
    "    (\"glove_big_svm\", glove_big_svm),\n",
    "    (\"glove_big_tfidf_svm\", glove_big_tfidf_svm),\n",
    "\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/PhilipADSo/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/PhilipADSo/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/Users/PhilipADSo/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/PhilipADSo/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/Users/PhilipADSo/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/PhilipADSo/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/Users/PhilipADSo/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/PhilipADSo/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/Users/PhilipADSo/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/PhilipADSo/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/Users/PhilipADSo/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/PhilipADSo/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/Users/PhilipADSo/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/PhilipADSo/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/Users/PhilipADSo/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/PhilipADSo/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/Users/PhilipADSo/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/PhilipADSo/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/Users/PhilipADSo/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/PhilipADSo/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/Users/PhilipADSo/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/PhilipADSo/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/Users/PhilipADSo/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/PhilipADSo/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/Users/PhilipADSo/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/PhilipADSo/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/Users/PhilipADSo/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/PhilipADSo/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/Users/PhilipADSo/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/PhilipADSo/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/Users/PhilipADSo/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/PhilipADSo/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/Users/PhilipADSo/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/PhilipADSo/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/Users/PhilipADSo/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/PhilipADSo/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/PhilipADSo/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/PhilipADSo/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/Users/PhilipADSo/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/PhilipADSo/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/Users/PhilipADSo/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/PhilipADSo/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/Users/PhilipADSo/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/PhilipADSo/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model                        score\n",
      "-------------------------  -------\n",
      "log_reg                     0.6152\n",
      "log_reg_tfidf               0.6087\n",
      "glove_small_tfidf_log_reg   0.5427\n",
      "glove_big_tfidf_log_reg     0.5426\n",
      "glove_small_log_reg         0.5423\n",
      "glove_big_log_reg           0.5423\n",
      "svc                         0.5143\n",
      "svc_tfidf                   0.4810\n",
      "glove_small_tfidf_svm       0.3660\n",
      "glove_big_tfidf_svm         0.3660\n",
      "glove_small_svm             0.3631\n",
      "glove_big_svm               0.3631\n"
     ]
    }
   ],
   "source": [
    "# need\n",
    "\n",
    "unsorted_scores = [(name, cross_val_score(model, trainDF['convtrain'], trainDF['labels'], cv=5).mean()) for name, model in all_models]\n",
    "scores = sorted(unsorted_scores, key=lambda x: -x[1])\n",
    "\n",
    "print (tabulate(scores, floatfmt=\".4f\", headers=(\"model\", 'score')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a29b7de80>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 6))\n",
    "sns.barplot(x=[name for name, _ in scores], y=[score for _, score in scores])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returns evaluation metrics\n",
    "def benchmark(model, data, labels, n):\n",
    "    '''\n",
    "    Ten-fold cross-validation with stratified sampling.\n",
    "    '''\n",
    "    test_size = 1 - (n / float(trainDF.shape[0]))\n",
    "    accuracyscores = []\n",
    "    precisionscores = []\n",
    "    recallscores = []\n",
    "    f1scores = []\n",
    "    f1scoremicro = []\n",
    "    f1scoremacro = []\n",
    "\n",
    "    confusionscores = []\n",
    "    sss = StratifiedShuffleSplit()\n",
    "    for train_index, test_index in sss.split(data, labels):\n",
    "        x_train, x_test = data[train_index], data[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        model.fit(x_train, y_train)\n",
    "        y_pred = model.predict(x_test)\n",
    "          \n",
    "        accuracyscores.append(accuracy_score(y_test, y_pred))\n",
    "        precisionscores.append(precision_score(y_test, y_pred, average=None))\n",
    "        recallscores.append(recall_score(y_test, y_pred, average=None))\n",
    "        f1scores.append(f1_score(y_test, y_pred, average=None))\n",
    "        f1scoremicro.append(f1_score(y_test, y_pred, average=\"micro\"))\n",
    "        f1scoremicro.append(f1_score(y_test, y_pred, average=\"macro\"))\n",
    "\n",
    "        confusionscores.append(confusion_matrix(y_test, y_pred))\n",
    " \n",
    "    return [np.mean(accuracyscores, axis=0),np.mean(precisionscores, axis=0),np.mean(recallscores, axis=0),np.mean(f1scores, axis=0),np.mean(confusionscores, axis=0),np.mean(f1scoremicro, axis=0),np.mean(f1scoremacro, axis=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/PhilipADSo/anaconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/Users/PhilipADSo/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/Users/PhilipADSo/anaconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/Users/PhilipADSo/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "# Fits the model with different training sizes\n",
    "train_sizes = [5, 8, 10, 13, 15, 18, 20, 30, 60, 230, 400, 600]\n",
    "table = []\n",
    "for name, model in all_models:\n",
    "    for n in train_sizes:\n",
    "        modelResults = benchmark(model, trainDF['convtrain'],trainDF['labels'], n)\n",
    "  \n",
    "        PreOthers, PreAngry, PreSad, PreHappy = modelResults[1]\n",
    "        RecOthers, RecAngry, RecSad, RecHappy = modelResults[2]\n",
    "        F1Others, F1Angry, F1Sad, F1Happy = modelResults[3]\n",
    "\n",
    "        table.append({'Model': name, \n",
    "                      'Accuracy': modelResults[0], \n",
    "                      'PreOthers': PreOthers,\n",
    "                      'PreAngry': PreAngry,\n",
    "                      'PreSad': PreSad,\n",
    "                      'PreHappy': PreHappy,\n",
    "                      'RecOthers': RecOthers,\n",
    "                      'RecAngry': RecAngry,\n",
    "                      'RecSad': RecSad,\n",
    "                      'RecHappy': RecHappy,\n",
    "                      'F1Others': F1Others,\n",
    "                      'F1Angry': F1Angry,\n",
    "                      'F1Sad': F1Sad,\n",
    "                      'F1Happy': F1Happy,\n",
    "                      'F1micro' : modelResults[5],\n",
    "                      'F1macro': modelResults[6],\n",
    "                      'Confusion': modelResults[4],\n",
    "                      'train_size': n})\n",
    "        \n",
    "df = pd.DataFrame(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# required to label each plot\n",
    "metric2labeler = {'Accuracy': \"Accuracy\",'PreOthers': \"Others class: Precision\",'PreAngry': \"Angry class: Precision\",'PreSad': \"Sad class: Precision\",'PreHappy': \"Happy class: Precision\",\n",
    "                'RecOthers':\"Others class: Recall\",'RecAngry':\"Angry class: Recall\",'RecSad':\"Sad class: Recall\",'RecHappy':\"Happy class: Recall\",\n",
    "                'F1Others':\"Others class: F1\",'F1Angry':'Angry class: F1Angry','F1Sad':\"Sad class: F1\",'F1Happy':\"Happy class: F1\",'F1micro':\"F1 Micro\",'F1macro':\"F1 Macro\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots how each metric changes with the size\n",
    "metricList = ['Accuracy','PreOthers','PreAngry','PreSad','PreHappy','RecOthers','RecAngry','RecSad','RecHappy','F1Others','F1Angry','F1Sad','F1Happy']\n",
    "\n",
    "for metricC in metricList:\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    fig = sns.pointplot(x='train_size', y=metricC, hue='Model', \n",
    "                        data=df[df.Model.map(lambda x: x in [\"svc\",\"svc_tfidf\",\"glove_small_svm\",\"glove_small_tfidf_svm\",\"glove_small_log_reg\",\"glove_small_tfidf_log_reg\",\"glove_big_log_reg\",\"glove_big_tfidf_log_reg\",\"glove_big_svm\",\"glove_big_tfidf_svm\"])])\n",
    "    sns.set_context(\"paper\", font_scale=1.5)\n",
    "    fig.set(ylabel=metricC)\n",
    "    fig.set(xlabel=\"labeled training examples\")\n",
    "    fig.set(title='{} against training size'.\\\n",
    "      format(metric2labeler[metricC]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot the confusion matrix\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "\n",
    "    # Only use the labels that appear in the data\n",
    "    classes = ['Others','Angry','Sad','Happy']\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'f'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting specific metrics\n",
    "for index, row in df.iterrows():\n",
    "        print( row['Model'],row['train_size'], row['Accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots the confusion matrix for each class and metric\n",
    "plt.figure(figsize=(15, 6))\n",
    "metricList = ['PreOthers','PreAngry','PreSad','PreHappy','RecOthers','RecAngry','RecSad','RecHappy','F1Others','F1Angry','F1Sad','F1Happy']\n",
    "\n",
    "for metricC in metricList:\n",
    "    for index, row in df.iterrows():\n",
    "        np.set_printoptions(precision=2)\n",
    "        print( row['Model'],row['train_size'])\n",
    "        # Plot non-normalized confusion matrix\n",
    "        # plot_confusion_matrix(row['Confusion'], classes=['Others','Angry','Sad','Happy'],\n",
    "        #                  title='Confusion matrix, without normalization')\n",
    "\n",
    "        # Plot normalized confusion matrix\n",
    "        plot_confusion_matrix(row['Confusion'], classes=['Others','Angry','Sad','Happy'], normalize=True,\n",
    "                          title='Normalized confusion matrix')\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saves result\n",
    "filename1 = 'Results'\n",
    "outfile1 = open(filename1,'wb')\n",
    "pickle.dump(df,outfile1)\n",
    "outfile1.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
